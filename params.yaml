prepare:
  train_size: 0.8
  test_size: 0.2
  random_state: 42
train:
  algorithm: "Neural_Network"                 # "XGBRegressor", "LGBMRegressor", "Neural_Network"                      
  
  # lgb     
  num_leaves: 29                      

  # xgb
  gamma: 0.6154687206061559                   
  
  # NN
  dropout: 0.6                                
  patience: 10                                
  epochs: 40                                
  batch_size: 128
  activation: "relu"  
  
  # lgb, xgb
  random_state: 42                            
  n_estimators: 289                           
  max_depth: 8   
  
  # lgb, xgb, NN
  learning_rate: 0.001 